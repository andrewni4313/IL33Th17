{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "import os, glob, re, pickle\n",
    "from functools import partial\n",
    "from collections import OrderedDict\n",
    "from cytoolz import compose\n",
    "import operator as op\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import scanpy as sc\n",
    "import anndata as ad\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pyscenic.export import export2loom, add_scenic_metadata\n",
    "from pyscenic.utils import load_motifs\n",
    "from pyscenic.transform import df2regulons\n",
    "from pyscenic.aucell import aucell\n",
    "\n",
    "from pyscenic.rss import regulon_specificity_scores\n",
    "from pyscenic.plotting import plot_rss\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from adjustText import adjust_text\n",
    "import seaborn as sns\n",
    "from pyscenic.binarization import binarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "# Helper function\n",
    "def derive_regulons(folder):\n",
    "    # Load enriched motifs.\n",
    "    motifs = load_motifs(folder+'motifs.csv')\n",
    "    motifs.columns = motifs.columns.droplevel(0)\n",
    "\n",
    "    def contains(*elems):\n",
    "        def f(context):\n",
    "            return any(elem in context for elem in elems)\n",
    "        return f\n",
    "\n",
    "    # For the creation of regulons we only keep the 10-species databases and the activating modules. We also remove the\n",
    "    # enriched motifs for the modules that were created using the method 'weight>50.0%' (because these modules are not part\n",
    "    # of the default settings of modules_from_adjacencies anymore.\n",
    "    motifs = motifs[\n",
    "        np.fromiter(map(compose(op.not_, contains('weight>50.0%')), motifs.Context), dtype=np.bool) & \\\n",
    "        np.fromiter(map(contains('mm9-tss-centered-10kb-10species.mc9nr', \n",
    "                                 'mm9-500bp-upstream-10species.mc9nr', \n",
    "                                 'mm9-tss-centered-5kb-10species.mc9nr'), motifs.Context), dtype=np.bool) & \\\n",
    "        np.fromiter(map(contains('activating'), motifs.Context), dtype=np.bool)]\n",
    "\n",
    "    # We build regulons only using enriched motifs with a NES of 3.0 or higher; we take only directly annotated TFs or TF annotated\n",
    "    # for an orthologous gene into account; and we only keep regulons with at least 10 genes.\n",
    "    regulons = list(filter(lambda r: len(r) >= 10, df2regulons(motifs[(motifs['NES'] >= 3.0) \n",
    "                                                                      & ((motifs['Annotation'] == 'gene is directly annotated')\n",
    "                                                                        | (motifs['Annotation'].str.startswith('gene is orthologous to')\n",
    "                                                                           & motifs['Annotation'].str.endswith('which is directly annotated for motif')))\n",
    "                                                                     ])))\n",
    "    \n",
    "    # Rename regulons, i.e. remove suffix.\n",
    "    regulons = list(map(lambda r: r.rename(r.transcription_factor), regulons))\n",
    "\n",
    "    # Pickle these regulons.\n",
    "    with open(folder+'regulons.dat', 'wb') as f:\n",
    "        pickle.dump(regulons, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SCENIC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the expression matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "SC_EXP_FNAME = \"Data/Cells/CD4/cd4.matrix.csv\"\n",
    "ex_matrix = pd.read_csv(SC_EXP_FNAME, sep=' ', header=0, index_col=0).T\n",
    "ex_matrix.index = ex_matrix.index.str.replace('.', '-')\n",
    "ex_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "__METADATA CLEANING__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_FOLDER = \"Data/Cells/CD4/\"\n",
    "df_cluster = pd.read_csv(BASE_FOLDER+\"cd4.clusters.csv\")\n",
    "df_tumor = pd.read_csv(BASE_FOLDER+\"cd4.tumor.csv\")\n",
    "df_cluster['x'] = pd.Series(df_cluster['x'], dtype=\"category\")\n",
    "df_metadata = df_cluster.merge(df_tumor, on=\"Unnamed: 0\")\n",
    "df_metadata.columns = [\"Cell ID\", \"Cluster\", \"Tumor\"]\n",
    "df_metadata = df_metadata.set_index(\"Cell ID\")\n",
    "df_metadata.to_csv(BASE_FOLDER+\"SCENIC/cd4.metadata.csv\", index=False)\n",
    "df_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regulons\n",
    "BASE_FOLDER = \"Data/Cells/CD4/SCENIC/\"\n",
    "derive_regulons(BASE_FOLDER)\n",
    "\n",
    "with open(BASE_FOLDER+'regulons.dat', 'rb') as f:\n",
    "    regulons = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_FOLDER = \"Data/Cells/CD4/SCENIC/\"\n",
    "REGULONS_DAT_FNAME = os.path.join(BASE_FOLDER, 'regulons.dat')\n",
    "with open(REGULONS_DAT_FNAME, 'rb') as f:\n",
    "    regulons = pickle.load(f)\n",
    "regulon_df = []\n",
    "for i,regulon in enumerate(regulons):\n",
    "    gene2weight = pd.Series(dict(regulon.gene2weight)).sort_values(ascending=False).round(2)\n",
    "    regulon_df.append([regulon.name, len(regulon.genes), regulon.score, list(zip(gene2weight.index, gene2weight))])\n",
    "regulon_df = pd.DataFrame(regulon_df, columns=[\"Regulon\", \"Size\", \"Score\", \"Genes\"]).sort_values(by=\"Score\", ascending=False).set_index('Regulon')\n",
    "regulon_df.to_excel(BASE_FOLDER+\"regulon_df.xlsx\")\n",
    "regulon_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate AUC Matrix\n",
    "auc_mtx = aucell(ex_matrix, regulons, seed=42)\n",
    "auc_mtx.to_csv(BASE_FOLDER+\"auc.csv\")\n",
    "auc_mtx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%capture\n",
    "# from tqdm import tqdm_notebook as tqdm\n",
    "# tqdm().pandas()\n",
    "\n",
    "# for start in tqdm(range(0, len(auc_mtx.columns))):\n",
    "#     print(auc_mtx.iloc[:,start:start+1].columns)\n",
    "#     binary_mtx, auc_thresholds = binarize(auc_mtx.iloc[:,start:start+1], seed=42, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# auc_mtx['Klf2'].to_csv(BASE_FOLDER+\"error_column.txt\")\n",
    "# auc_mtx = auc_mtx.drop('Klf2', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Binary Matrix\n",
    "binary_mtx, auc_thresholds = binarize(auc_mtx, seed=42, num_workers=1)\n",
    "binary_mtx.to_csv(BASE_FOLDER+\"binary.csv\")\n",
    "binary_mtx"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
